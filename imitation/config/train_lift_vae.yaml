num_episodes: 2
output_dir: ./output

# Environment
obs_dim: 19
action_dim: 7
pred_horizon: 16



# Training parameters
num_epochs: 100
model_path: ./weights/lift_vae_overfit.pt

obs_keys: &obs_keys ['object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']


env_runner: 
  _target_: imitation.env_runner.robomimic_lowdim_runner.RobomimicEnvRunner
  output_dir: ${output_dir}
  action_horizon: ${pred_horizon}
  env:
    _target_: imitation.env.robomimic_lowdim_wrapper.RobomimicLowdimWrapper
    max_steps: ${max_steps}
    task: "Lift"

policy:
  _target_: imitation.policy.vae_policy.VAEPolicy
  model:
    _target_: imitation.model.vae.VAE
    # input is action_dim*obs_horizon
    input_dim: ${eval:'${action_dim}*${pred_horizon}'}
    hidden_dims: [64, 32, 16, 8]
    latent_dim: 4
  env: ${env_runner.env}
  dataset:
    _target_: imitation.dataset.robomimic_lowdim_dataset.RobomimicLowdimDataset
    dataset_path: ./data/lift_low_dim_v141.hdf5
    obs_keys: *obs_keys
    pred_horizon: ${pred_horizon}
  ckpt_path: ./weights/lift_vae_overfit.pt


agent:
  _target_: imitation.agent.robomimic_lowdim_agent.RobomimicLowdimAgent