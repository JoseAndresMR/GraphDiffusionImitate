{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Diffusion Models on Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.datasets import ZINC\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing, GATConv, GAT\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n",
      "Extracting /tmp/ZINC/molecules.zip\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n",
      "Processing...\n",
      "Processing train dataset: 100%|██████████| 220011/220011 [00:16<00:00, 13174.82it/s]\n",
      "Processing val dataset: 100%|██████████| 24445/24445 [00:02<00:00, 8901.46it/s] \n",
      "Processing test dataset: 100%|██████████| 5000/5000 [00:00<00:00, 12933.02it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# instanciate the dataset\n",
    "dataset = ZINC(root='/tmp/ZINC', transform=None, pre_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[18, 1], edge_index=[2, 36], edge_attr=[36], y=[1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = dataset[1]\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1,\n",
       "        2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absence of edges should be an edge type, attribute 0\n",
    "# fully connect graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2184])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMasking node mechanism\\n1. Masked node (x = -1)\\n2. Connected to all other nodes in graph by masked edges (edge_attr = -1)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Masking node mechanism\n",
    "1. Masked node (x = -1)\n",
    "2. Connected to all other nodes in graph by masked edges (edge_attr = -1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0],\n",
       "         [4],\n",
       "         [2],\n",
       "         [0],\n",
       "         [1],\n",
       "         [4],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2]]),\n",
       " 'edge_index': tensor([[ 0,  1,  1,  1,  2,  2,  3,  3,  3,  4,  5,  5,  5,  6,  7,  7,  7,  8,\n",
       "           8,  9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "          16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 21],\n",
       "         [ 1,  0,  2, 13,  1,  3,  2,  4,  5,  3,  3,  6,  7,  5,  5,  8, 12,  7,\n",
       "           9,  8, 10,  9, 11, 10, 12,  7, 11,  1, 14, 21, 13, 15, 14, 16, 15, 17,\n",
       "          21, 16, 18, 17, 19, 18, 20, 19, 21, 13, 16, 20]]),\n",
       " 'edge_attr': tensor([1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1,\n",
       "         2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1]),\n",
       " 'y': tensor([-0.2184])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 10, 11, 3, 17, 15, 16, 1, 2, 6, 0, 4, 12, 5, 9, 8, 7, 14]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Node decay ordering, for forward absorbing pass\n",
    "* Naive: random\n",
    "Later on, use diffusion ordering network\n",
    "'''\n",
    "\n",
    "def node_decay_ordering(datapoint):\n",
    "    # create random list of nodes\n",
    "    return torch.randperm(datapoint.x.shape[0]).tolist()\n",
    "\n",
    "def is_masked(datapoint, node=None):\n",
    "    if node is None:\n",
    "        return datapoint.x == -1\n",
    "    return datapoint.x[node] == -1\n",
    "\n",
    "\n",
    "\n",
    "def mask_node(datapoint, selected_node):\n",
    "    '''\n",
    "    datapoint.x: node feature matrix\n",
    "    datapoint.edge_index: edge index matrix\n",
    "    datapoint.edge_attr: edge attribute matrix\n",
    "    datapoint.y: target value\n",
    "\n",
    "    ** Changes datapoint inplace\n",
    "    '''\n",
    "    # mask node\n",
    "    datapoint.x[selected_node] = -1\n",
    "    # mask edges\n",
    "    datapoint.edge_attr[datapoint.edge_index[0] == selected_node] = 0\n",
    "    datapoint.edge_attr[datapoint.edge_index[1] == selected_node] = 0\n",
    "    return datapoint\n",
    "\n",
    "node_decay_ordering(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](media/don.png)\n",
    "\n",
    "![Alt text](media/don_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionOrderingNetwork(nn.Module):\n",
    "    '''\n",
    "    at each diffusion step t, we sample from this network to select a node \n",
    "    v_sigma(t) to be absorbed and obtain the corresponding masked graph Gt\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 node_feature_dim,\n",
    "                 num_node_types,\n",
    "                 num_edge_types,\n",
    "                 num_layers=3,\n",
    "                 out_channels=1):\n",
    "        super(DiffusionOrderingNetwork, self).__init__()\n",
    "\n",
    "        # add positional encodings into node features\n",
    "        self.embedding = nn.Embedding(100, node_feature_dim)\n",
    "\n",
    "        self.gat = GAT(\n",
    "            in_channels=node_feature_dim,\n",
    "            out_channels=node_feature_dim,\n",
    "            hidden_channels=6 * 6,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0,\n",
    "            heads=6,\n",
    "        )\n",
    "\n",
    "\n",
    "    def positionalencoding(self, lengths, permutations):\n",
    "        '''\n",
    "        From Chen, et al. 2021 (Order Matters: Probabilistic Modeling of Node Sequences for Graph Generation)\n",
    "        '''\n",
    "        # length = sum([len(perm) for perm in permutations])\n",
    "        l_t = len(permutations[0])\n",
    "        # pes = [torch.zeros(length, self.d_model) for length in lengths]\n",
    "        pes = torch.split(torch.zeros((sum(lengths), self.d_model), device=self.device), lengths)\n",
    "        # print(pes[0].device)\n",
    "        position = torch.arange(0, l_t, device=self.device).unsqueeze(1) + 1\n",
    "        div_term = torch.exp((torch.arange(0, self.d_model, 2, dtype=torch.float, device=self.device) *\n",
    "                              -(math.log(10000.0) / self.d_model)))\n",
    "        # test = torch.sin(position.float() * div_term)\n",
    "        for i in range(len(lengths)):\n",
    "            pes[i][permutations[i], 0::2] = torch.sin(position.float() * div_term)\n",
    "            pes[i][permutations[i], 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        pes = torch.cat(pes)\n",
    "        return pes\n",
    "\n",
    "    def forward(self, G, p=None):\n",
    "        h = self.gat(G.x.float(), G.edge_index)\n",
    "\n",
    "        # TODO augment node features with positional encodings\n",
    "        # if p is not None:\n",
    "        #     # p = self.positionalencoding(G.batch_num_nodes().tolist(), p) original from Chen et al.\n",
    "        #     p = self.positionalencoding(G.x.shape[0], p)\n",
    "        #     h = h + p\n",
    "        \n",
    "        # softmax over nodes\n",
    "        h = F.softmax(h, dim=0)\n",
    "        \n",
    "        return h # outputs probabilities for a categorical distribution over nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0544, 0.0550, 0.0558, 0.0584, 0.0593, 0.0616, 0.0595, 0.0586, 0.0567,\n",
      "        0.0576, 0.0551, 0.0526, 0.0522, 0.0523, 0.0529, 0.0535, 0.0523, 0.0522],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_ord_net = DiffusionOrderingNetwork(node_feature_dim=1,\n",
    "                                        num_node_types=dataset.x.unique().shape[0],\n",
    "                                        num_edge_types=3,\n",
    "                                        num_layers=3,\n",
    "                                        out_channels=1)\n",
    "sigma_t_dist = diff_ord_net(point)\n",
    "print(sigma_t_dist.flatten())\n",
    "# sample from categorical distribution to get node to mask\n",
    "# TODO only on the samples that are not masked\n",
    "# sigma_t = F.softmax(sigma_t_dist.flatten(), dim=0)\n",
    "torch.distributions.Categorical(probs=sigma_t_dist.flatten()).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Diffusion Process\n",
    "\n",
    "Node ordering $\\sigma$ using diffusion ordering network. Exactly one node decays at a time.\n",
    "\n",
    "At each step $t$, distribution of $t$-th node is conditioned on original graph $G$ and generated node ordering $\\sigma$ up to $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_decay_ordering(datapoint):\n",
    "    p = datapoint.clone()\n",
    "    node_order = []\n",
    "    for i in range(p.x.shape[0]):\n",
    "        # use diffusion ordering network to get probabilities\n",
    "        sigma_t_dist = diff_ord_net(p, i)\n",
    "        # sample from categorical distribution to get node to mask\n",
    "        # TODO only on the samples that are not masked\n",
    "        unmasked = ~is_masked(p)\n",
    "        sigma_t = torch.distributions.Categorical(probs=sigma_t_dist[unmasked].flatten()).sample()\n",
    "        \n",
    "        # get node index\n",
    "        sigma_t = torch.where(unmasked.flatten())[0][sigma_t.long()]\n",
    "        node_order.append(sigma_t)\n",
    "        # mask node\n",
    "        p = mask_node(p, sigma_t)\n",
    "    return node_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5),\n",
       " tensor(11),\n",
       " tensor(1),\n",
       " tensor(12),\n",
       " tensor(15),\n",
       " tensor(6),\n",
       " tensor(3),\n",
       " tensor(14),\n",
       " tensor(8),\n",
       " tensor(16),\n",
       " tensor(9),\n",
       " tensor(10),\n",
       " tensor(13),\n",
       " tensor(4),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(2)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_decay_ordering(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Diffusion (Generative) Process\n",
    "\n",
    "Denoising network $p_ \\theta (G_t | G_{t+1})$ is a graph attention network (GAT). (Vanilla GAT)\n",
    "\n",
    "For now, simple graph convolutional network (GCN) is used.\n",
    "\n",
    "\n",
    "** Initially, the graph is fully connected and masked, so in the paper they only keep the masked node to be denoised during the generation step. \n",
    "\n",
    "For now, we will just use the whole graph as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMessage passing\\nCustom message passing function\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Message passing\n",
    "Custom message passing function\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure attentive message passing is done correctly.\n",
    "\n",
    "\n",
    "![Alt text](media/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import Linear, Parameter\n",
    "class MessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MessagePassingLayer, self).__init__(aggr='mean', flow=\"target_to_source\")  # 'add' aggregation for simplicity\n",
    "\n",
    "        self.W = nn.Linear(in_channels, out_channels)\n",
    "        # self.attention = nn.Linear(2 * in_channels, attention_dim)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.W.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j # TODO change to adapt attention mechanism\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Attention mechanism\n",
    "        # alpha = F.softmax(self.attention(torch.cat([x[row], x[col]], dim=-1)), dim=-1)\n",
    "        # alpha = F.dropout(alpha, p=0.5)\n",
    "        # messages = alpha.view(-1, 1) * edge_attr\n",
    "        # messages = scatter_add(messages, col, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        # h = self.W(torch.cat([x, messages], dim=-1))\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](media/architecture.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenoisingNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_feature_dim,\n",
    "                 num_node_types,\n",
    "                 num_edge_types,\n",
    "                 num_layers,\n",
    "                 out_channels):\n",
    "        super(DenoisingNetwork, self).__init__()\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=num_node_types, embedding_dim=node_feature_dim)\n",
    "\n",
    "        print(node_feature_dim, num_node_types, num_edge_types, num_layers, out_channels)\n",
    "\n",
    "        self.GAT = GAT(\n",
    "            in_channels=node_feature_dim,\n",
    "            out_channels=node_feature_dim,\n",
    "            hidden_channels=128,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0,\n",
    "        )\n",
    "\n",
    "        # Custom message passing layers\n",
    "        # self.message_passing_layers = nn.ModuleList([\n",
    "        #     GATConv(node_feature_dim, node_feature_dim, heads=1, dropout=0.6) for _ in range(num_layers)\n",
    "        # ])\n",
    "        \n",
    "        # Node type prediction\n",
    "        self.node_type_prediction = nn.Linear(node_feature_dim, num_node_types) # Use only element of the new node\n",
    "        \n",
    "        # Edge type prediction\n",
    "        self.edge_type_prediction = nn.Linear(node_feature_dim, num_edge_types) # Use all elements (connections to other nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        '''\n",
    "        Outputs: \n",
    "        new_node_type: type of new node to be unmasked\n",
    "        new_edge_type: types of new edges from previous nodes to the one to be unmasked\n",
    "        '''\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = x.squeeze()\n",
    "        # Make sure x is float\n",
    "        x = x.long()\n",
    "        edge_index = edge_index.long()\n",
    "\n",
    "\n",
    "        h = self.embedding_layer(x)\n",
    "\n",
    "        # for layer in self.message_passing_layers:\n",
    "        #     h = layer(h, edge_index, edge_attr)\n",
    "\n",
    "\n",
    "        h = self.GAT(h, edge_index)\n",
    "\n",
    "\n",
    "        # Node type prediction\n",
    "        node_type_logits = self.node_type_prediction(h)\n",
    "        # Applying softmax for the multinomial distribution\n",
    "        node_type_probs = F.softmax(node_type_logits, dim=-1)  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Edge type prediction\n",
    "        edge_type_logits = self.edge_type_prediction(h)\n",
    "        # Applying softmax for the multinomial distribution\n",
    "        edge_type_probs = F.softmax(edge_type_logits, dim=-1)\n",
    "        \n",
    "        \n",
    "        return node_type_probs, edge_type_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 28 3 7 1\n"
     ]
    }
   ],
   "source": [
    "# num_features\n",
    "dn = DenoisingNetwork(\n",
    "    node_feature_dim=dataset.num_features,\n",
    "    num_node_types=dataset.x.unique().shape[0],\n",
    "    num_edge_types=3,\n",
    "    num_layers=7,\n",
    "    out_channels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = point.clone()\n",
    "node_type_probs, edge_type_probs = dn(p)\n",
    "edge_type_probs # connections of new node to all previous nodes\n",
    "node_type_probs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For now, use MSE / Reconstruction error instead of loss function from the paper.\n",
    "\n",
    "\n",
    "Optimize by sampling multiple ($M$) diffusion trajectories, thereby enabling training both the diffusion ordering network $q_ϕ(σ|G_0)$ and the denoising network\n",
    "$p_θ(Gt|G_t+1)$ using gradient descent.\n",
    "\n",
    "Create M trajectories (sequence of graphs) for each training graph. Where node decay order is sampled from $q_ϕ(σ|G_0)$ (or random, initially).\n",
    "\n",
    "Train denoising network to minimize the negative VLB using SGD.\n",
    "\n",
    "Diffusion ordering network can be updated with common RL optimization methods, e.g., the REINFORCE algorithm. Creating M trajectories and computing the negative VLB to obtain rewards, and then updating the parameters of the diffusion ordering network using the REINFORCE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 28 3 7 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hjs3bwsx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>███▇▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>-1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">overfit</strong> at: <a href='https://wandb.ai/caiofreitas/ARGD/runs/hjs3bwsx' target=\"_blank\">https://wandb.ai/caiofreitas/ARGD/runs/hjs3bwsx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231025_191651-hjs3bwsx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hjs3bwsx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/caio/workspace/GraphDiffusionImitate/notebooks/wandb/run-20231025_192217-589ld7i9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caiofreitas/ARGD/runs/589ld7i9' target=\"_blank\">overfit_nozerograd</a></strong> to <a href='https://wandb.ai/caiofreitas/ARGD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caiofreitas/ARGD' target=\"_blank\">https://wandb.ai/caiofreitas/ARGD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caiofreitas/ARGD/runs/589ld7i9' target=\"_blank\">https://wandb.ai/caiofreitas/ARGD/runs/589ld7i9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/caiofreitas/ARGD/runs/589ld7i9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f17f75f8e50>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use wandb to log the model\n",
    "import wandb\n",
    "\n",
    "dn = DenoisingNetwork(\n",
    "    node_feature_dim=dataset.num_features,\n",
    "    num_node_types=dataset.x.unique().shape[0],\n",
    "    num_edge_types=3,\n",
    "    num_layers=7,\n",
    "    out_channels=1\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "        project=\"ARGD\",\n",
    "        group=f\"v0.21\",\n",
    "        name=f\"overfit_nozerograd\",\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"policy\": \"train\",\n",
    "            \"n_epochs\": 10000,\n",
    "            \"batch_size\": 1,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](media/optimizer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/tmp/ipykernel_3858/1387443523.py:19: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  node_order = torch.range(0, graph.x.shape[0]-1).long()\n",
      "Epoch: 26, Loss: 0.0000:  52%|█████▏    | 26/50 [00:42<00:39,  1.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb Cell 23\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m G_pred \u001b[39m=\u001b[39m G_tplus1\u001b[39m.\u001b[39mclone()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# predict node type\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m node_type_probs, edge_type_probs \u001b[39m=\u001b[39m dn(G_tplus1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m node_type_probs \u001b[39m=\u001b[39m node_type_probs[node]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#  Apply multinomial distribution\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# node_dist = torch.distributions.Multinomial(probs=node_type_probs.squeeze(), total_count=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# node_type = node_dist.sample()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# add node type to node\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb Cell 23\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_layer(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# for layer in self.message_passing_layers:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m#     h = layer(h, edge_index, edge_attr)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGAT(h, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Node type prediction\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caio/workspace/GraphDiffusionImitate/notebooks/ARGD.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m node_type_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_type_prediction(h)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/imitation/lib/python3.8/site-packages/torch_geometric/nn/models/basic_gnn.py:224\u001b[0m, in \u001b[0;36mBasicGNN.forward\u001b[0;34m(self, x, edge_index, edge_weight, edge_attr, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001b[0m\n\u001b[1;32m    222\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[i](x, edge_index, edge_weight\u001b[39m=\u001b[39medge_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_edge_attr:\n\u001b[0;32m--> 224\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs[i](x, edge_index, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[i](x, edge_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/imitation/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:252\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe usage of \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39msimultaneously is currently not yet supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m form\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[39m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_updater(edge_index, alpha\u001b[39m=\u001b[39;49malpha, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m    254\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m    255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, alpha\u001b[39m=\u001b[39malpha, size\u001b[39m=\u001b[39msize)\n",
      "File \u001b[0;32m~/mambaforge/envs/imitation/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:531\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[0;34m(self, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_user_args, edge_index, size,\n\u001b[1;32m    528\u001b[0m                           kwargs)\n\u001b[1;32m    530\u001b[0m edge_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39medge_update\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 531\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_update(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49medge_kwargs)\n\u001b[1;32m    533\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_update_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    534\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (edge_index, kwargs), out)\n",
      "File \u001b[0;32m~/mambaforge/envs/imitation/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:296\u001b[0m, in \u001b[0;36mGATConv.edge_update\u001b[0;34m(self, alpha_j, alpha_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    294\u001b[0m alpha \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(alpha, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_slope)\n\u001b[1;32m    295\u001b[0m alpha \u001b[39m=\u001b[39m softmax(alpha, index, ptr, size_i)\n\u001b[0;32m--> 296\u001b[0m alpha \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mdropout(alpha, p\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m alpha\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39m, p, training)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_VF.py:25\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39msuper\u001b[39m(VFModule, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(name)\n\u001b[1;32m     23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train denoising diffusion model\n",
    "# use node decay ordering\n",
    "\n",
    "optimizer = torch.optim.Adam(dn.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "loss_fcn = torch.nn.NLLLoss() # TODO use appropriate loss function (possibly NLLLoss)\n",
    "# require grad for model\n",
    "dn.train()\n",
    "\n",
    "M = 4 # number of diffusion trajectories to be created for each graph\n",
    "\n",
    "\n",
    "with tqdm(range(50)) as pbar:\n",
    "    for batch in pbar:\n",
    "        graph = dataset[0]\n",
    "        # print(f\"Generating trajectories for graph\")\n",
    "        # node decay ordering, accoding to node_decay_ordering\n",
    "        original_data = graph.clone()\n",
    "        diffusion_trajectories = []\n",
    "        node_order = torch.range(0, graph.x.shape[0]-1).long()\n",
    "        for m in range(M):\n",
    "            # node_order = node_decay_ordering(graph)\n",
    "            \n",
    "            # create diffusion trajectory\n",
    "            diffusion_trajectory = [original_data]\n",
    "            masked_data = graph.clone()\n",
    "            for node in node_order:\n",
    "                masked_data = masked_data.clone()\n",
    "                \n",
    "                masked_data = mask_node(masked_data, node)\n",
    "                diffusion_trajectory.append(masked_data)\n",
    "\n",
    "            diffusion_trajectories.append(diffusion_trajectory)\n",
    "        \n",
    "        # predictions & loss\n",
    "        for diffusion_trajectory in diffusion_trajectories:\n",
    "            G_0 = diffusion_trajectory[0]\n",
    "            # optimizer.zero_grad()\n",
    "            # node_order = node_decay_ordering(G_0) \n",
    "            for t in range(1, len(diffusion_trajectory)-1):\n",
    "                node = node_order[len(diffusion_trajectory)-t-1]\n",
    "                G_t = diffusion_trajectory[t]\n",
    "                # transform to float\n",
    "                G_t.x = G_t.x.float()\n",
    "                G_t.edge_index = G_t.edge_index.float()\n",
    "\n",
    "                G_tplus1 = diffusion_trajectory[t+1].clone()\n",
    "                # transform to float\n",
    "                G_tplus1.x = G_tplus1.x.float()\n",
    "                G_tplus1.edge_index = G_tplus1.edge_index.float()\n",
    "\n",
    "                G_pred = G_tplus1.clone()\n",
    "                \n",
    "\n",
    "                # predict node type\n",
    "                node_type_probs, edge_type_probs = dn(G_tplus1)\n",
    "\n",
    "                node_type_probs = node_type_probs[node]\n",
    "                \n",
    "                #  Apply multinomial distribution\n",
    "                # node_dist = torch.distributions.Multinomial(probs=node_type_probs.squeeze(), total_count=1)\n",
    "                # node_type = node_dist.sample()\n",
    "                # edge_dist = torch.distributions.Multinomial(probs=edge_type_probs.squeeze(), total_count=G_tplus1.x.shape[0])\n",
    "                # node_connections = edge_dist.sample()\n",
    "\n",
    "                # add node type to node\n",
    "                node_dist = torch.distributions.Categorical(probs=node_type_probs.squeeze())\n",
    "                node_type = node_dist.sample()\n",
    "                # print(node_type)\n",
    "                # G_pred.x[node] = node_type\n",
    "                # sample edge type\n",
    "                # new_connections = torch.multinomial(node_connections_probs.squeeze(), num_samples=1, replacement=True)\n",
    "                '''\n",
    "                TODO make sure you \n",
    "                \"predict the connections of the new node to all previous nodes at once \n",
    "                                        using a mixture of multinomial distribution\"\n",
    "                '''\n",
    "                # add new connections to edge_attr\n",
    "                # for i in  range(len(node_connections)):\n",
    "                #     new_connection = node_connections[i]\n",
    "                #     if new_connection != 0:\n",
    "                #         G_pred.edge_attr[G_pred.edge_index[0] == i] = new_connection\n",
    "                \n",
    "                # calculate loss\n",
    "                # loss = loss_fcn(G_t.x.float(), G_pred.x.float())\n",
    "\n",
    "                loss = loss_fcn(node_type_probs.reshape(1, -1), G_t.x[node].long())\n",
    "\n",
    "                # backprop\n",
    "                loss.backward()\n",
    "\n",
    "                # DEBUG if gradients are not None\n",
    "                # for name, param in dn.named_parameters():\n",
    "                #     if param.grad != None and torch.sum(param.grad) != 0:\n",
    "                #         print(name, param.grad.shape, torch.sum(param.grad))\n",
    "                \n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "                # log loss\n",
    "                pbar.set_description(f\"Epoch: {batch}, Loss: {loss.item()%10:.4f}\")\n",
    "                wandb.log({\"loss\": loss.item()})\n",
    "        # save model\n",
    "        torch.save(dn.state_dict(), \"ardm_model.pt\")\n",
    "            \n",
    "            \n",
    "    '''\n",
    "    TODO: edge_attributes have to be used. The masked nodes can be identified through them. There'll never be error in edge_index\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [5]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_trajectory[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_pred = diffusion_trajectory[-1].clone()\n",
    "G_pred.x = G_pred.x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 3])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_connections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "forward_pass = [G_pred]\n",
    "\n",
    "for i in node_order:\n",
    "    # 1 diffusion step for each node\n",
    "    with torch.no_grad():\n",
    "        node_type_probs, edge_type_probs = dn(G_pred)\n",
    "        # sample node type\n",
    "        node_dist = torch.distributions.Categorical(probs=node_type_probs.squeeze())\n",
    "        node_type = node_dist.sample()[i]\n",
    "        print(node_type)\n",
    "        edge_dist = torch.distributions.Multinomial(probs=edge_type_probs.squeeze(), total_count=G_tplus1.x.shape[0])\n",
    "        node_connections = edge_dist.sample()\n",
    "        G_pred.x[i] = node_type\n",
    "        # add new connections to edge_attr\n",
    "        # for i in  range(len(node_connections)):\n",
    "        #     new_connection = node_connections[i]\n",
    "        #     if new_connection != 0:\n",
    "        #         G_pred.edge_attr[G_pred.edge_index[0] == i] = new_connection\n",
    "        \n",
    "        forward_pass.append(G_pred.clone())\n",
    "    # print(G_pred.x)\n",
    "    # print(G_pred.edge_attr)\n",
    "    # print(G_pred.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass[-1].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imitation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
