{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Diffusion Models on Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.datasets import ZINC\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n",
      "Extracting /tmp/ZINC/molecules.zip\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n",
      "Processing...\n",
      "Processing train dataset: 100%|██████████| 220011/220011 [00:14<00:00, 15604.59it/s]\n",
      "Processing val dataset: 100%|██████████| 24445/24445 [00:02<00:00, 10267.08it/s]\n",
      "Processing test dataset: 100%|██████████| 5000/5000 [00:00<00:00, 12979.67it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# instanciate the dataset\n",
    "dataset = ZINC(root='/tmp/ZINC', transform=None, pre_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[26, 1], edge_index=[2, 58], edge_attr=[58], y=[1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = dataset[2]\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "        1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absence of edges should be an edge type, attribute 0\n",
    "# fully connect graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0851])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMasking node mechanism\\n1. Masked node (x = 0)\\n2. Connected to all other nodes in graph by masked edges (edge_attr = -1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Masking node mechanism\n",
    "1. Masked node (x = -1)\n",
    "2. Connected to all other nodes in graph by masked edges (edge_attr = -1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [0],\n",
       "         [5],\n",
       "         [4],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [5],\n",
       "         [2],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " 'edge_index': tensor([[ 0,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  6,  6,  6,  7,  8,\n",
       "           8,  8,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 14, 14, 15, 15,\n",
       "          15, 16, 17, 17, 17, 18, 19, 19, 20, 20, 21, 21, 22, 22, 22, 23, 23, 23,\n",
       "          24, 24, 25, 25],\n",
       "         [ 1,  0,  2,  1,  3,  2,  4, 22,  3,  5, 20,  4,  6,  5,  7,  8,  6,  6,\n",
       "           9, 14,  8, 10,  9, 11, 19, 10, 12, 15, 11, 13, 14, 12,  8, 12, 11, 16,\n",
       "          17, 15, 15, 18, 19, 17, 10, 17,  4, 21, 20, 22,  3, 21, 23, 22, 24, 25,\n",
       "          23, 25, 23, 24]]),\n",
       " 'edge_attr': tensor([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "         1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "         1, 2, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'y': tensor([1.0851])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 7,\n",
       " 12,\n",
       " 1,\n",
       " 18,\n",
       " 20,\n",
       " 14,\n",
       " 13,\n",
       " 25,\n",
       " 16,\n",
       " 22,\n",
       " 23,\n",
       " 6,\n",
       " 9,\n",
       " 19,\n",
       " 4,\n",
       " 10,\n",
       " 24,\n",
       " 2,\n",
       " 11,\n",
       " 8,\n",
       " 15,\n",
       " 3,\n",
       " 5,\n",
       " 21,\n",
       " 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Node decay ordering, for forward absorbing pass\n",
    "* Naive: random\n",
    "Later on, use diffusion ordering network\n",
    "'''\n",
    "\n",
    "def node_decay_ordering(datapoint):\n",
    "    # create random list of nodes\n",
    "    return torch.randperm(datapoint.x.shape[0]).tolist()\n",
    "\n",
    "\n",
    "\n",
    "def mask_node(datapoint, selected_node):\n",
    "    '''\n",
    "    datapoint.x: node feature matrix\n",
    "    datapoint.edge_index: edge index matrix\n",
    "    datapoint.edge_attr: edge attribute matrix\n",
    "    datapoint.y: target value\n",
    "\n",
    "    ** Changes datapoint inplace\n",
    "    '''\n",
    "    # mask node\n",
    "    datapoint.x[selected_node] = -1\n",
    "    # mask edges\n",
    "    datapoint.edge_attr[datapoint.edge_index[0] == selected_node] = -1\n",
    "    datapoint.edge_attr[datapoint.edge_index[1] == selected_node] = -1\n",
    "    return datapoint\n",
    "\n",
    "node_decay_ordering(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Diffusion Process\n",
    "\n",
    "Node orderint $\\sigma$ randomly sampled. Exactly one node decays at a time.\n",
    "\n",
    "At each step $t$, distribution of $t$-th node is conditioned on original graph $G$ and generated node ordering $\\sigma$ up to $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in node_decay_ordering(point):\n",
    "    mask_node(point, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Diffusion (Generative) Process\n",
    "\n",
    "Denoising network $p_ \\theta (G_t | G_{t+1})$ is a graph attention network (GAT). (Vanilla GAT)\n",
    "\n",
    "For now, simple graph convolutional network (GCN) is used.\n",
    "\n",
    "\n",
    "** Initially, the graph is fully connected and masked, so in the paper they only keep the masked node to be denoised during the generation step. \n",
    "\n",
    "For now, we will just use the whole graph as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Message passing\n",
    "Custom message passing function\n",
    "'''\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing, GATConv\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import Linear, Parameter\n",
    "class MessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MessagePassingLayer, self).__init__(aggr='mean', flow=\"target_to_source\")  # 'add' aggregation for simplicity\n",
    "\n",
    "        self.W = nn.Linear(in_channels, out_channels)\n",
    "        # self.attention = nn.Linear(2 * in_channels, attention_dim) # No attention for now\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.W.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Attention mechanism\n",
    "        # alpha = F.softmax(self.attention(torch.cat([x[row], x[col]], dim=-1)), dim=-1)\n",
    "        # alpha = F.dropout(alpha, p=0.5)\n",
    "        # messages = alpha.view(-1, 1) * edge_attr\n",
    "        # messages = scatter_add(messages, col, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        # h = self.W(torch.cat([x, messages], dim=-1))\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, norm=norm) # , edge_attr=edge_attr\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "class DenoisingNetwork(nn.Module):\n",
    "    def __init__(self, node_feature_dim, num_node_types, num_edge_types, num_layers, out_channels):\n",
    "        super(DenoisingNetwork, self).__init__()\n",
    "\n",
    "        # self.embedding_layer = nn.Embedding(num_embeddings=node_feature_dim, embedding_dim=node_feature_dim)\n",
    "        \n",
    "        \n",
    "        self.message_passing_layers = nn.ModuleList([\n",
    "            MessagePassingLayer(node_feature_dim, node_feature_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Node type prediction\n",
    "        self.node_type_prediction = nn.Linear(node_feature_dim, num_node_types)\n",
    "        \n",
    "        # Edge type prediction\n",
    "        self.edge_type_prediction = nn.Linear(node_feature_dim, num_edge_types)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # Make sure x is float\n",
    "        x = x.long()\n",
    "        edge_index = edge_index.long()\n",
    "        edge_attr = edge_attr.float()\n",
    "\n",
    "\n",
    "        # h = self.embedding_layer(x) # bypass embedding\n",
    "        h = x\n",
    "\n",
    "        for layer in self.message_passing_layers:\n",
    "            h = layer(h, edge_index)\n",
    "\n",
    "        # Node type prediction\n",
    "        node_type_logits = self.node_type_prediction(h)\n",
    "        node_type_probs = F.softmax(node_type_logits, dim=-1)  # Applying softmax for the multinomial distribution\n",
    "\n",
    "\n",
    "        # Edge type prediction\n",
    "        edge_type_logits = self.edge_type_prediction(h)\n",
    "        edge_type_probs = F.softmax(edge_type_logits, dim=-1)  # Applying softmax for the multinomial distribution\n",
    "\n",
    "        return node_type_probs, edge_type_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolutional Network, with message passing\n",
    "class OldDenoisingNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 num_layers,\n",
    "                 dropout):\n",
    "        super(DenoisingNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.gcn = torch_geometric.nn.GCNConv(input_dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout) \n",
    "        # embedding layer\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # x: node feature matrix\n",
    "        # edge_index: edge index matrix\n",
    "        # edge_attr: edge attribute matrix\n",
    "        # batch: batch vector\n",
    "\n",
    "        # make sure node features are floats\n",
    "        x = x.float()\n",
    "        # make sure edge attributes are floats\n",
    "        edge_attr = edge_attr.float()\n",
    "        # make sure edge index is ints\n",
    "        edge_index = edge_index.long()\n",
    "\n",
    "        # pass through GCN\n",
    "        x = self.gcn(x, edge_index, edge_attr)\n",
    "\n",
    "        # batch normalization\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # pass through linear layer\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # softmax\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odn = OldDenoisingNetwork(input_dim=dataset.num_features,\n",
    "#                         hidden_dim=64,\n",
    "#                         output_dim=dataset.num_features,\n",
    "#                         num_layers=3,\n",
    "#                         dropout=0.5)\n",
    "dn = DenoisingNetwork(\n",
    "    node_feature_dim=dataset.num_features,\n",
    "    num_node_types=dataset.num_features,\n",
    "    num_edge_types=dataset.num_features,\n",
    "    num_layers=3,\n",
    "    out_channels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = point.clone()\n",
    "pred_x, pred_edges = dn(p)\n",
    "pred_edges.shape # connections of new node to all previous nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For now, use MSE / Reconstruction error instead of loss function from the paper.\n",
    "\n",
    "\n",
    "Optimize by sampling multiple ($M$) diffusion trajectories, thereby enabling training both the diffusion ordering network $q_ϕ(σ|G_0)$ and the denoising network\n",
    "$p_θ(Gt|G_t+1)$ using gradient descent.\n",
    "\n",
    "Create M trajectories (sequence of graphs) for each training graph. Where node decay order is sampled from $q_ϕ(σ|G_0)$ (or random, initially).\n",
    "\n",
    "Train denoising network to minimize the negative VLB using SGD.\n",
    "\n",
    "Diffusion ordering network can be updated with common RL optimization methods, e.g., the REINFORCE algorithm. Creating M trajectories and computing the negative VLB to obtain rewards, and then updating the parameters of the diffusion ordering network using the REINFORCE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Variable class\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Loss: 0.0455: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nTODO: edge_attributes have to be used. The masked nodes can be identified through them. There'll never be error in edge_index\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train denoising diffusion model\n",
    "# use node decay ordering\n",
    "\n",
    "optimizer = torch.optim.Adam(dn.parameters(), lr=0.0001)\n",
    "# require grad for model\n",
    "dn.requires_grad_(True)\n",
    "\n",
    "\n",
    "M = 5 # number of diffusion trajectories to be created for each graph\n",
    "\n",
    "\n",
    "with tqdm(range(100)) as pbar:\n",
    "    for batch in pbar:\n",
    "        graph = dataset[batch]\n",
    "        # print(f\"Generating trajectories for graph\")\n",
    "        # node decay ordering, accoding to node_decay_ordering\n",
    "        original_data = graph.clone()\n",
    "        diffusion_trajectories = []\n",
    "        for m in range(M):\n",
    "            node_order = node_decay_ordering(graph)\n",
    "            # create diffusion trajectory\n",
    "            diffusion_trajectory = [original_data]\n",
    "            masked_data = graph.clone()\n",
    "            for node in node_order:\n",
    "                masked_data = masked_data.clone()\n",
    "                \n",
    "                masked_data = mask_node(masked_data, node)\n",
    "                diffusion_trajectory.append(masked_data)\n",
    "\n",
    "            diffusion_trajectories.append(diffusion_trajectory)\n",
    "        \n",
    "        # predictions & loss\n",
    "        for diffusion_trajectory in diffusion_trajectories:\n",
    "            G_0 = diffusion_trajectory[0]\n",
    "            for t in range(1, len(diffusion_trajectory)-1):\n",
    "                G_t = diffusion_trajectory[t]\n",
    "                # transform to float\n",
    "                G_t.x = G_t.x.float()\n",
    "                G_t.edge_index = G_t.edge_index.float()\n",
    "\n",
    "                G_tplus1 = diffusion_trajectory[t+1].clone()\n",
    "                # transform to float\n",
    "                G_tplus1.x = G_tplus1.x.float()\n",
    "                G_tplus1.edge_index = G_tplus1.edge_index.float()\n",
    "                G_tplus1.x.requires_grad = True\n",
    "                G_tplus1.edge_index.requires_grad = True\n",
    "\n",
    "                G_pred = G_tplus1.clone()\n",
    "\n",
    "                # predict node type\n",
    "                node_type_probs, node_connections_probs = dn(G_tplus1)\n",
    "                node_type_probs.requires_grad_()\n",
    "                node_connections_probs.requires_grad_()\n",
    "                # sample node type\n",
    "                pred_node_type = torch.distributions.multinomial.Multinomial(1, node_type_probs.squeeze())\n",
    "                # add node type to node\n",
    "                G_pred.x[node] = pred_node_type.sample()[node]\n",
    "                # sample edge type\n",
    "                new_connections = torch.distributions.multinomial.Multinomial(1, node_connections_probs.squeeze()).sample()\n",
    "                # add new connections to edge_attr\n",
    "                for i in  range(len(new_connections)):\n",
    "                    new_connection = new_connections[i]\n",
    "                    if new_connection != -1:\n",
    "                        G_pred.edge_attr[G_pred.edge_index[0] == i] = new_connection\n",
    "                # calculate loss\n",
    "                node_loss = torch.nn.functional.mse_loss(G_t.x.float(), G_pred.x.float())\n",
    "                # connections_loss = torch.nn.functional.mse_loss(G_t.edge_index[0].float(), G_pred.edge_index[0].float())\n",
    "                loss = node_loss #+ connections_loss\n",
    "                # backprop\n",
    "                loss.backward()\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "                # log loss\n",
    "                pbar.set_description(f\"Epoch: {batch}, Loss: {loss.item()%10:.4f}\")\n",
    "            \n",
    "        \n",
    "'''\n",
    "TODO: edge_attributes have to be used. The masked nodes can be identified through them. There'll never be error in edge_index\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test denoising diffusion model on diffusion trajectory\n",
    "G_pred = diffusion_trajectory[-1].clone()\n",
    "node_type_probs, node_connections_probs = dn(diffusion_trajectory[-1])\n",
    "node_type_probs.requires_grad_()\n",
    "node_connections_probs.requires_grad_()\n",
    "# sample node type\n",
    "pred_node_type = torch.distributions.multinomial.Multinomial(1, node_type_probs.squeeze())\n",
    "# add node type to node\n",
    "G_pred.x[node] = pred_node_type.sample()[node]\n",
    "# sample edge type\n",
    "new_connections = torch.distributions.multinomial.Multinomial(1, node_connections_probs.squeeze()).sample()\n",
    "# add new connections to edge_attr\n",
    "for i in  range(len(new_connections)):\n",
    "    new_connection = new_connections[i]\n",
    "    if new_connection != -1:\n",
    "        G_pred.edge_attr[G_pred.edge_index[0] == i] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2539200343.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ==\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imitation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
